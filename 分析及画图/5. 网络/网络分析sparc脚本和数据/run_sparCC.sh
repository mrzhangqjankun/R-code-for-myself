#!/usr/bin/bash

#Go to the course folder
cd ~/Desktop/EBI2014/Thursday/coocurrences

#We create a folder for keeping the bootstraped data
mkdir -p pvals

#We run sparCC on our data with 5 iterations (recommended >= 100)
SparCC.py otu_table_filtered_50.tsv -i 5 --cor_file=icomm_cor_sparcc_5.out

#Make 10 (recommended >= 100) simulated datasets used to get pseudo p-values.
#Simulated datasets are generated by assigning each OTU in each sample an abundance
#that is randomly drawn (w. replacement) from the abundances of the OTU in all samples.
MakeBootstraps.py otu_table_filtered_50.tsv -n 5 -o pvals/boot

#We run sparCC one time for each simulated dataset
for i in {0..10}; do printf "Bootstrap number: $i\n";SparCC.py pvals/boot_${i}.txt -i 5 --cor_file=pvals/sim_cor_${i}.txt 2&>1; done

#Compute pseudo p-vals from a set correlations obtained from shuffled data.
#Pseudo p-vals are the percentage of times a correlation at least as extreme as the "real"
#one was observed in simulated datasets.
#p-values can be either:
#   two-sided (considering only the correlation magnitude)
#   one-sided (accounting for the sign of correlations).

#In our case we will only consider the correlation magnitude
PseudoPvals.py icomm_cor_sparcc_5.out pvals/sim_cor 10 -o icomm_pvals_sparcc_5.out -t 'two_sided'

#Time to go back to R
